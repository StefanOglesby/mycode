{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-IQ/Probing_OpenEndeds/blob/main/ProbingOfOpenEndeds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lEogerN8sKO5",
        "outputId": "e3281afa-ae3e-475a-c371-8ed0b2caa572"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Probe: \"What exactly do you like about the taste of this product?\"'"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#######  chat conversation with memory for the api\n",
        "1+1\n",
        "!pip3 install openai\n",
        "# !pip3 install mistralai\n",
        "\n",
        "# imports\n",
        "import openai\n",
        "\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from logging import exception\n",
        "import sys\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "# Set your API key\n",
        "openai.api_key = userdata.get(\"openAIKey\")\n",
        "\n",
        "### define probing_data\n",
        "probing_data = {\"en\": {\"system_prompt\": \"\"\"You are a chatbot with the task of writing a probe for more  specificity in a neutral, friendly, encouraging way in English language, based on respondents' answers to open-ended questions. The question is indicated with \"question:\", and the respondent's answer is indicated with \"answer:\".\n",
        "Examples: question: \"What do you like about this product\" /  answer: \"the colour\" / style: \"what exactly\" // probe: \"what exactly do you like about the colour?\"\n",
        "question: \"What do you dislike about this product\" / answer: \"It does not seem to be convenient\" /style:\"can you tell me more\" // probe: \"Can you tell me more why you say it is not convenient?\"\n",
        "question: \"Why would you rather not buy this product\" / answer: \"it is not clear what it is all about\" /style: \"please share more\" // probe: \"Would you share more about why it is not clear\" \"\"\" , \"styles\": [\"\"\" \"what exactly\" \"\"\", \"\"\" \"can you tell me more\" \"\"\",\n",
        "                 \"\"\" \"can you expand on\" \"\"\", \"\"\" \"please share more\" \"\"\"]},\n",
        "                \"de\": {\"system_prompt\": \"\"\"You are a chatbot with the task of writing a probe for more specificity in a neutral, friendly, encouraging way in German language, based on respondents' answers to open-ended questions. The question is indicated with \"question:\", and the respondent's answer is indicated with \"answer:\"..\n",
        "Examples: question: „Was gefällt Ihnen an diesem Produkt?“ / answer: \"die Farbe\" / style \"was genau\" // probe: \"Was genau gefällt Ihnen an der Farbe?\"\n",
        "question: \"Was gefällt Ihnen an diesem Produkt nicht?\" / answer: \"Es scheint nicht praktisch zu sein\" / style: \"können Sie mir mehr dazu sagen\" // probe: \"Können Sie mir mehr dazu sagen, warum Sie finden, dass es nicht praktisch ist?“\n",
        "question: \"Warum würden Sie dieses Produkt lieber nicht kaufen?\" / answer: \"Es ist nicht klar, worum es geht\" / style: \"erzählen Sie mehr\" // Probe: \"Können Sie mehr darüber erzählen, warum es nicht klar ist\" \"\"\", \"styles\":[\"\"\" \"was genau\" \"\"\", \"\"\" \"können Sie mir mehr dazu sagen\" \"\"\" ,\n",
        "                 \"\"\" \"können Sie das näher erläutern\" \"\"\", \"\"\" \"erzählen Sie mehr\" \"\"\" ] }}\n",
        "\n",
        "# inspect\n",
        "probing_data[\"en\"][\"system_prompt\"]\n",
        "probing_data[\"de\"][\"system_prompt\"]\n",
        "probing_data[\"en\"][\"styles\"]\n",
        "probing_data[\"de\"][\"styles\"]\n",
        "\n",
        "\n",
        "# Convert and write JSON object to file\n",
        "\n",
        "## import json\n",
        "with open(\"/content/drive/MyDrive/probing_data/probing_data.json\", \"wb\") as f:\n",
        "    f.write(json.dumps(probing_data).encode(\"utf-8\"))\n",
        "\n",
        "with open(\"/content/drive/MyDrive/probing_data/probing_data.json\", 'r') as fp:\n",
        "    test_data = json.load(fp)\n",
        "\n",
        "test_data[\"en\"][\"styles\"]\n",
        "\n",
        "## print(probing_data[\"en\"][\"styles\"][randint(1,4)-1])\n",
        "\n",
        "\n",
        "def so_probe1(q_and_a,probing_data,temperature):\n",
        "    so_styles = probing_data[\"styles\"]\n",
        "    style = so_styles[randint(1,4)-1]\n",
        "    user_prompt = \"\"\"Please write a probe for the following:\"\"\" + q_and_a +       \"\"\" style:\"\"\" +  style\n",
        "\n",
        "    user_dict = {\"role\": \"user\", \"content\":user_prompt}\n",
        "    messages = [{\"role\": \"system\", \"content\":probing_data[\"system_prompt\"]}]\n",
        "    messages.append(user_dict)\n",
        "\n",
        "    try:\n",
        "      response = openai.chat.completions.create(\n",
        "      # Specify the correct model\n",
        "      model=\"gpt-3.5-turbo-0125\",\n",
        "      messages = messages,\n",
        "      temperature = temperature,\n",
        "      )\n",
        "\n",
        "      probe = response.choices[0].message.content\n",
        "\n",
        "    except:\n",
        "      probe = \"API not available\"\n",
        "\n",
        "\n",
        "    return probe\n",
        "\n",
        "\n",
        "q_and_a = \"\"\"question: \"What do you like about this product\"\n",
        "    answer: \"it tastes great\" \"\"\"\n",
        "\n",
        "q_and_a = \"\"\"question: \"Was gefällt Ihnen an diesem Produkt\"\n",
        "   answer: \"der gute Geschmack\" \"\"\"\n",
        "\n",
        "language = \"en\"\n",
        "\n",
        "so_probe1(q_and_a, probing_data[language], temperature = 0)\n",
        "\n",
        "so_probe1(q_and_a, test_data[\"de\"], temperature = 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N18KnFdTBHrI"
      },
      "source": [
        "# **Obsolete function with system prompt f-string and built-in styles english only**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTRnFwp7BUdd"
      },
      "outputs": [],
      "source": [
        "system_prompt  = \"\"\"You are a chatbot with the task of writing a probe for more  specificity in a neutral, friendly, encouraging way based on respondents' answers to open-ended questions. The question is indicated with \"question:\", and the respondent's answer is indicated with \"answer:\".\n",
        "Examples: question: \"What do you like about this product\" /  answer: \"the colour\" / style: \"what exactly\" // probe: \"what exactly do you like about the colour?\"\n",
        "question: \"What do you dislike about this product\" / answer: \"It does not seem to be convenient\" /style:\"can you tell me more\" // probe: \"Can you tell me more why you say it is not convenient?\"\n",
        "question: \"Why would you rather not buy this product\" / answer: \"it is not clear what it is all about\" /style: \"share more\" // probe: \"Would you share more about why it is not clear\"\n",
        "\"\"\n",
        "\n",
        "\n",
        "\n",
        "def so_probe(q_and_a,system_prompt,temperature):\n",
        "    so_styles = [\"\"\" \"what exactly\" \"\"\", \"\"\" \"can you tell me more\" \"\"\",\n",
        "                 \"\"\" \"can you expand on\" \"\"\", \"\"\" \"please share more\" \"\"\"]\n",
        "    style = so_styles[randint(1,4)-1]\n",
        "    user_prompt = \"\"\"Please write a probe for the following:\"\"\" + q_and_a +       \"\"\" style:\"\"\" +  style\n",
        "\n",
        "    user_dict = {\"role\": \"user\", \"content\":user_prompt}\n",
        "    messages = [{\"role\": \"system\", \"content\":system_prompt}]\n",
        "    messages.append(user_dict)\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "    # Specify the correct model\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages = messages,\n",
        "    temperature = temperature,\n",
        "    )\n",
        "\n",
        "    probe = response.choices[0].message.content\n",
        "\n",
        "    return probe"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOEK5bZwBSjw9P1thMvVnbN",
      "history_visible": true,
      "include_colab_link": true,
      "mount_file_id": "1-hyrLqCZIOfxlI0er8BOCUrfbB1YUXHI",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
